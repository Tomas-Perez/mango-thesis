\chapter{Experimental Results} \label{ch:ExperimentalResults}
In this Chapter we will cover the experimental phase of our work. First comes a description of our setup and methodology, covering the hardware and software utilized as well as the chosen benchmarks and metrics. Then we will present our results and provide our analysis in order to fuel further research and development in the MANGO software stack.

During this experimental campaign, our goals were to:
\begin{itemize}
    \item Measure the performance of MANGO with respect to other available programming models.
    \item Compare the programmability of MANGO with respect to other available programming models.
    \item Analyze where are the main overheads of the current MANGO implementation and how they can be reduced.
\end{itemize}

\section{Setup and Methodology} \label{sect:setup-methodology}
All our tests were run on a Dell XPS 9570 laptop. This particular model is equipped with an Intel Core i7 8750H CPU, 16 GB RAM and an NVIDIA GeForce GTX 1050 Ti GPU with Max-Q Design (4GB VRAM). In terms of Operating System, the machine was running Ubuntu 18.04.2 LTS 64-bit (Kernel Version: 5.4.0-48-generic).

For reproducibility, the versions of the software run are as follows:
\begin{itemize}
    \item CUDA 11.0
    \item OpenCL 1.2 CUDA (Driver version: 450.51.06)
    \item gcc 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)
    \item clang 6.0.0-1ubuntu2
    \item Python 3.6.9
    \item Cython 0.29.23
\end{itemize}

In order to compare the performance of MANGO to CUDA and OpenCL we used a subset of the Rodinia Benchmark Suite (Version 3.1) \cite{rodinia}, provided by the University of Virginia. In particular, we chose the HotSpot and PathFinder benchmarks.

HotSpot (HS) is a thermal simulation tool, presented in \cite{hotspot}, which is used for estimating processor temperature based on an architectural floor plan and simulated power measurements. The benchmark includes the 2D transient thermal simulation kernel of HotSpot, which iteratively solves a series of differential equations for block temperatures. The inputs to the program are power and initial temperatures of a square N x N grid. Each output cell in the grid represents the average temperature value of the corresponding area of the chip.

During our experiments, the size of the Grid (N) was progressively increased in order to increase the load on the GPU. The number of threads spawned for computation as well as the size of the input buffers and output buffers scale with O(N\textsuperscript{2}). The number of kernel executions is determined by the amount of iterations desired. This parameter is kept fixed, resulting in 16 kernel executions to compute 128 iterations of the algorithm for all HotSpot benchmarks.

PathFinder (PF) uses dynamic programming to find a path on a 2-D grid from the bottom row to the top row with the smallest accumulated weights, where each step of the path moves straight ahead or diagonally ahead. It iterates row by row, each node picks a neighboring node in the previous row that has the smallest accumulated weight, and adds its own weight to the sum.

Like with HotSpot, we also increased the size of the input grid (N) in order to increase the GPU load when running the PathFinder benchmarks. The dimensions of the grid were also kept symmetrical, as in the number of columns is equal to the number of rows (N x N). In this case, increasing the number of columns increases the number of threads spawn to compute the shortest path. The number of rows, on the other hand, increases the number of kernel executions. In addition, the size of the grid increases the dimensions of the input buffer with O(N\textsuperscript{2}), the output however only increases linearly, with O(N), as only the values of the columns are needed.

During our testing we realized that PathFinder most certainly lacks global GPU memory access optimizations. This is indicated by its poor memory bandwidth performance coupled with the fact that the algorithm requires continuous access to the input rows in order to calculate each iteration. In addition, the operations performed by pathfinder are simple comparisons and a single integer addition. It is important to also note that these comparisons are integer minimum operations, which do not generate branches \cite{ptx_isa}.

We still decided to keep PathFinder in our comparison as it is a good example of what happens when there is a need to run a kernel multiple times in a single benchmark and how the different systems scale with increasing numbers of kernel launches.

Finally, in order to cover our lack of memory bound applications due to the issues mentioned with PathFinder, we added an AXPY benchmark. AXPY stands for "A X plus Y", as noted by the name, it performs the following operation:

\[
    z \leftarrow a*x+y
\]

This same operation is also implemented in BabelStream \cite{babelstream}, a memory bandwidth benchmark for heterogenous systems based on STREAM \cite{stream}, which names it "Triad". 

A breakdown of the three benchmarks chosen can be seen in table \ref{tab:benchmark-breakdown}.

\begin{table}[ht]
    \centering
    \begin{tabular}{l|c|c}
    Benchmark & Dwarves & Performance characteristic \\ \hline
    HotSpot & Structured Grid & Compute intensive \\
    PathFinder & Dynamic Programming & Multiple kernel launches \\
    AXPY & Basic Linear Algebra & Memory intensive          
    \end{tabular}
    \captionsetup{justification=centering}
    \caption{Breakdown of benchmarks used}
    \label{tab:benchmark-breakdown}
\end{table}

\subsection{Performance metrics}

To evaluate performance in both HotSpot and PathFinder, we will measure:

\begin{itemize}
    \item Total execution time: time since the beginning of the proper benchmark (i.e. after all input initialization and I/O) and the end (after all resource deallocations, but before checking output results).
    \item Kernel execution time: time since the launch of a kernel and the end of its execution.
    \item Buffer write time: time to write data to the device, i.e transfer data from the host to the device.
    \item Buffer read time: time to read data from the device, i.e. transfer data from the device to the host.
\end{itemize}

For AXPY, we will measure the performance of the different systems as the percentage of theoretical peak bandwidth they can achieve. We will take into account both GPU memory bandwidth, measuring accesses to GPU global memory, and PCI-E bandwidth, measuring data transfers between the Host and the Device and vice versa.

For GPU memory, the theoretical peak bandwidth is given by plugging the memory clock rate and bus width into the following formula:

\[
    GBW_{peak} = \frac{C * 10^6 * (B/8) * 2}{10^9}
\]

Where:
\begin{itemize}
    \item $GBW_{peak}$ is the theoretical peak GPU VRAM bandwidth in GB/s.
    \item $C$ is the memory clock rate in MHz.
    \item $B$ is the memory bus width in bits.
\end{itemize}

With a memory clock rate of 3504 MHz and 128-bit of bus width, the GTX 1050 Ti in our test bench achieves a theoretical peak of 112.128 GB/s.

To measure the effective bandwidth achieved by each model we use the following formula:

\[
    GBW_{effective} = \frac{R_B + W_B}{t * 10^9}
\]

Where:
\begin{itemize}
    \item $GBW_{effective}$ is the effective GPU VRAM bandwidth in GB/s.
    \item $R_B$ is the number of bytes read per kernel.
    \item $W_B$ is the number of bytes written per kernel.
    \item $t$ is the kernel execution time in seconds.
\end{itemize}

The two previous formulae were taken from \cite{perf_metrics_cuda}.

In terms of PCI-E bandwidth, our video card presents a PCI-E 3.0 x16 connection which could achieve a peak bandwidth of 15.754GB/s.

In a very similar way as how we measure effective bandwidth for GPU memory, we can measure the effective transfer bandwidth:

\[
    TBW_{effective} = \frac{T_B}{t * 10^9}
\]

Where:
\begin{itemize}
    \item $TBW_{effective}$ is the effective transfer bandwidth in GB/s.
    \item $T_B$ is the number of bytes transferred.
    \item $t$ is the transfer time in seconds.
\end{itemize}

In AXPY we are not interested in the scaling over different input sizes but in the bandwidths achieved with large inputs. A large input maximizes the amount of memory to transfer and access, meaning that a larger part of the available bandwidth can be exploited.  

It is important to note that for all benchmarks in both CUDA and OpenCL we execute the set of benchmarks twice. Once to measure the total execution time of the entire benchmark and another to measure each individual component. As all our measurements in these models are done externally (i.e. we cannot make intrusive profiling modifications like with MANGO) they could incur in extra overhead due to the need of forcing synchronization between the host and the device in order to make measurements. For example, OpenCL buffer writes are usually enqueued in a \texttt{CommandQueue} and executed asynchronously, to measure them we forced a synchronous transfer by calling \texttt{clFinish} on the \texttt{CommandQueue}.

Finally, in the case of MANGO, we performed our measurements on two different sectors of the application. As mentioned previously, the HHAL library is implemented in a client-server arrangement, where the communication between client and server is performed via socket. This provides us with an easy way to run the HHAL in a separate cluster in the future. However, this adds extra communication overhead to the MANGO client which is not present in either CUDA nor OpenCL, as they both run directly on the same host machine. Due to this, we measure performance both on the client side (taking into account IPC overhead) but also directly on the HHAL server (in order to compare our implementation with CUDA and OpenCL).

\subsection{Programmability}

To compare the programmability of each model we count the number of lines of code (LOC) required for each implementation of the HotSpot and PathFinder benchmarks. To compute the LOC we do not take into account comments or blank lines. Also, we ignore any line of code related to debugging, extra code needed to profile the OpenCL and CUDA benchmarks or checking computation results. This last point is particularly significant on the MANGO benchmarks which usually compare their results with the CUDA benchmarks to ensure that the implementation is working correctly. Finally, the original code from the Rodinia Benchmarks was adapted in order to follow a consistent style across all implementations. 

In addition to the LOC metric, to have a more direct comparison of the size of the MANGO implementations to the CUDA and OpenCL ones we also use a Relative Difference metric (RD). RD calculates the percentage difference in LOC between MANGO and a different implementation. We define RD as follows:

\[
    RD = \frac{LOC_{impl} - LOC_{MANGO}}{LOC_{MANGO}} * 100
\]

Thus, a positive RD indicates that a given implementation requires more LOC than MANGO, while a negative RD indicates that the implementation requires less LOC.

\section{Results}

In this section we will present the results of our experiments. First we will make performance comparisons against CUDA and OpenCL, then we will cover the overhead experimented by the client due to IPC with the HHAL server and finally we will analyze the programmability improvements achieved by MANGO over CUDA and OpenCL.

\subsection{Performance}

\subsubsection{HotSpot}

Starting with HotSpot, we can see that performance across all metrics is very similar for all implementations. In addition, all programming models follow the same scaling as input size increases. 

The overhead presented by MANGO in this benchmark is noticeable, but not significant. For example, when running with a grid size of 8192 x 8192, CUDA is the fastest completing the entire execution in \textasciitilde 2516ms while MANGO takes \textasciitilde 2692ms, a difference of only 6.5\%. 

\begin{figure}
    \centering
    \resizebox{!}{180pt}{
        \input{img/figures/hotspot/total_duration_mean.tex}
    }
    \captionsetup{justification=centering}
    \caption{Mean total execution time for HotSpot}
    \label{fig:hotspot_total_duration_mean}
\end{figure}

When decomposing the benchmark into its different aspects we can see that the overhead is most significant for buffer writes, as seen in figure \ref{fig:hotspot_buffer_transfers_mean}. Here CUDA is 8.4\% faster than MANGO for the same 256 megabyte transfer. Still, MANGO keeps up the pace with OpenCL, which is only 1\% faster.

\begin{figure}%
    \centering
    \subfloat[\centering Mean buffer write time]{{
        \resizebox{!}{160pt}{
        \input{img/figures/hotspot/buffer_writes_mean.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean buffer read time]{{
        \resizebox{!}{160pt}{
            \input{img/figures/hotspot/buffer_reads_mean.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean buffer transfer times for HotSpot}%
    \label{fig:hotspot_buffer_transfers_mean}%
\end{figure}

Actually, the most important overhead is the one linked to kernel executions, which are performed more frequently than buffer writes (only 2 buffer writes versus 16 kernel executions) and also require more time to be performed. In this case, CUDA and OpenCL are 6.2\% and 3.7\% faster respectively for the largest grid size used. This can be seen in figure \ref{fig:hotspot_kernel_executions_mean}.

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/hotspot/kernel_executions_mean.tex}
    }
    \captionsetup{justification=centering}
    \caption{Mean kernel execution time for HotSpot}
    \label{fig:hotspot_kernel_executions_mean}
\end{figure}

The influence of kernel execution time can be seen in the benchmark breakdown in figure \ref{fig:hotspot_breakdown} which compares how the total running time of the benchmark is distributed among the different aspects of the execution, plus some miscellaneous operations which are not particularly relevant for this benchmark. These breakdowns are generated using the biggest input size for HotSpot, 8192 x 8192. In the figure it is clearly pictured how kernel execution time takes up more than 90\% of the total benchmark time across all programming models.

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/hotspot/breakdown.tex}
    }
    \captionsetup{justification=centering}
    \caption{Benchmark breakdown for HotSpot}
    \label{fig:hotspot_breakdown}
\end{figure}

\subsubsection{PathFinder}

Moving on to PathFinder we can see a much more significant difference in the performance of MANGO and OpenCL with respect to CUDA in figure \ref{fig:pathfinder_total_duration_mean}. In addition, a clear increase in the steepness of the curve can be seen in the case of MANGO, as it steers away from the OpenCL implementation. This would indicate that there is some noticeable overhead present in the kernel executions, as they increase in number along with the input size of PathFinder.

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/pathfinder/total_duration_mean.tex}
    }
    \captionsetup{justification=centering}
    \caption{Mean total execution time for PathFinder}
    \label{fig:pathfinder_total_duration_mean}
\end{figure}

Figure \ref{fig:pathfinder_kernel_executions_mean} confirms our suspicion, as there is a clear separation between the kernel execution times of MANGO and the ones of CUDA and OpenCL, which are quite similar with each other. Comparing the the time taken for the biggest input size, CUDA is 20\% faster for each kernel executed, while OpenCL is 17.9\% faster.

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/pathfinder/kernel_executions_mean.tex}
    }
    \captionsetup{justification=centering}
    \caption{Mean kernel execution time for PathFinder}
    \label{fig:pathfinder_kernel_executions_mean}
\end{figure}

Focusing now on buffer transfers, as seen in figure \ref{fig:pathfinder_buffer_transfers_mean}, OpenCL gains the advantage for the bigger buffer sizes written by PathFinder. Meanwhile MANGO stays in line with the pure CUDA implementation, although with some overhead still present. In terms of buffer reads, MANGO pulls ahead with the largest buffer size, with CUDA and OpenCL being 28.9\% and 43\% slower respectively. However it is important to note that the buffers read as a result are significantly smaller than the ones written as input, so these initial differences could be negligible for larger buffer sizes, as seen for HotSpot in figure \ref{fig:hotspot_buffer_transfers_mean}.

\begin{figure}%
    \centering
    \subfloat[\centering Mean buffer write time]{{
        \resizebox{!}{160pt}{
        \input{img/figures/pathfinder/buffer_writes_mean.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean buffer read time]{{
        \resizebox{!}{160pt}{
            \input{img/figures/pathfinder/buffer_reads_mean.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean buffer transfer times for PathFinder}%
    \label{fig:pathfinder_buffer_transfers_mean}%
\end{figure}

Finally, we move on to the benchmark breakdown which, similarly to the one for HotSpot, it is generated with the largest input size for PathFinder, 16384 x 16384. Here in figure \ref{fig:pathfinder_breakdown} we can clearly see that the factor that most contributes to the difference in performance between the different implementations are actually the miscellaneous tasks (plus resource allocation for MANGO), taking up around 50\% of the running time. These include all the boilerplate and preparations required to setup the different execution environments. While this is very minimal in the case of CUDA, as it is a single-source model, where kernel and host code are precompiled and loaded together, the setup is much more significant for MANGO and OpenCL. Both OpenCL and MANGO require loading a separate kernel file which involves I/O operations. After that OpenCL also adds kernel compilation and device setup, while MANGO requires communication with BBQUE to perform resource allocation and deallocation. These aspects are not significant for HotSpot as the total running time is much longer and the overhead of the setup is constant, no matter the input size.

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/pathfinder/breakdown.tex}
    }
    \captionsetup{justification=centering}
    \caption{Benchmark breakdown for PathFinder}
    \label{fig:pathfinder_breakdown}
\end{figure}

\subsubsection{AXPY}

In AXPY we move straight to the mean kernel execution time in figure \ref{fig:axpy_kernel_executions_mean} where we can see that CUDA performs 12.4\% faster than MANGO, while OpenCL is only 7\% faster for the same size input.

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/axpy/kernel_executions_mean.tex}
    }
    \captionsetup{justification=centering}
    \caption{Mean kernel execution times for AXPY}
    \label{fig:axpy_kernel_executions_mean}
\end{figure}

As we know that AXPY is purely memory bandwidth bound, we can translate this kernel execution times to memory bandwidth measurements as seen in figure \ref{fig:axpy_bandwidth_mean}. In this figure we can see the percentage of theoretical peak bandwidth achieved by each programming model.

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/axpy/bandwidth_mean.tex}
    }
    \captionsetup{justification=centering}
    \caption{Mean GPU memory bandwidth for AXPY}
    \label{fig:axpy_bandwidth_mean}
\end{figure}

What is interesting is that if we look at the maximum bandwidth achieved by each model MANGO is able to beat both CUDA and OpenCL, being 1\% and 4.5\% faster than each programming model respectively. This indicates that our implementation does not inherently pose a limit to the performance that could be achieved by the GPU when compared to pure CUDA and the overhead is affected by varying external factors, such as background processes or Operating System context switches. 

\begin{figure}
    \centering
    \resizebox{!}{160pt}{
        \input{img/figures/axpy/bandwidth_max.tex}
    }
    \captionsetup{justification=centering}
    \caption{Max GPU memory bandwidth for AXPY}
    \label{fig:axpy_bandwidth_max}
\end{figure}

Finally, we look at the transfer times achieved between the host and the device and vice versa and how these translate to the percentage of PCI-E bandwidth achieved. These comparisons can be seen in figures \ref{fig:axpy_buffer_transfers_mean} and \ref{fig:axpy_buffer_transfers_bandwidth_mean} respectively. In terms of device-to-host transfers, the difference in performance is negligible, although none of the models provide an optimal speed for the available PCI-E connection. For host-to-device transfers, MANGO gets second place, with CUDA being 6\% faster and OpenCL 7\% slower. Still, none of the models achieve close to maximum usage of the PCI-E connection.

\begin{figure}%
    \centering
    \subfloat[\centering Mean buffer write time]{{
        \resizebox{!}{160pt}{
        \input{img/figures/axpy/transfer_time_writes_mean.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean buffer read time]{{
        \resizebox{!}{160pt}{
            \input{img/figures/axpy/transfer_time_reads_mean.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean buffer transfer times for AXPY}%
    \label{fig:axpy_buffer_transfers_mean}%
\end{figure}

\begin{figure}%
    \centering
    \subfloat[\centering Mean host to device transfer bandwidth]{{
        \resizebox{!}{160pt}{
        \input{img/figures/axpy/transfer_bandwidth_htod_mean.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean device to host transfer bandwidth]{{
        \resizebox{!}{160pt}{
            \input{img/figures/axpy/transfer_bandwidth_dtoh_mean.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean buffer transfer bandwidths for AXPY}%
    \label{fig:axpy_buffer_transfers_bandwidth_mean}%
\end{figure}

\subsection{IPC}

As mentioned in section \ref{sect:setup-methodology}, the previous benchmarks did not take into account the overhead added by inter process communication between the libmango client and the HHAL server. Here we will focus on this part separately to evaluate our communication scheme and how it can be improved.

Starting with figure \ref{fig:hotspot_total_and_kernel_executions_mean_ipc} we can see how the total duration of the HotSpot benchmark increases when taking IPC into account, and how this difference scales with larger input sizes. This however is not linked with the kernel execution time, which is perfectly in line with the benchmark without any IPC. 

\begin{figure}%
    \centering
    \subfloat[\centering Mean total execution time]{{
        \resizebox{!}{160pt}{
        \input{img/figures/hotspot/total_duration_mean_ipc.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean kernel execution time]{{
        \resizebox{!}{160pt}{
            \input{img/figures/hotspot/kernel_executions_mean_ipc.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean total and kernel execution times for HotSpot}%
    \label{fig:hotspot_total_and_kernel_executions_mean_ipc}%
\end{figure}

For the same metrics, PathFinder sees a much steeper increase in execution time along with the execution time. As can be see in figure \ref{fig:pathfinder_total_and_kernel_executions_mean_ipc}b, this is more closely linked with the kernel execution time which here shows a clear separation between IPC and no IPC. In addition, the PathFinder kernel is run more times as the input size increases, so this overhead piles up with multiple executions.

If we compare these results with the ones in HotSpot we can conclude that the overhead experienced with IPC is fixed and does not scale with input size. This is supported by the fact that HotSpot kernel executions are an order of magnitude larger than PathFinder executions (150ms for HotSpot versus 90/40μs for PathFinder).

\begin{figure}%
    \centering
    \subfloat[\centering Mean total execution time]{{
        \resizebox{!}{160pt}{
        \input{img/figures/pathfinder/total_duration_mean_ipc.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean kernel execution time]{{
        \resizebox{!}{160pt}{
            \input{img/figures/pathfinder/kernel_executions_mean_ipc.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean total and kernel execution times for PathFinder}%
    \label{fig:pathfinder_total_and_kernel_executions_mean_ipc}%
\end{figure}

Buffer transfers, as expected, are affected significantly more by IPC as the amount of data that needs to be transferred is much higher than what is needed to launch a kernel. Both figure \ref{fig:hotspot_buffer_transfers_mean_ipc} and figure \ref{fig:pathfinder_buffer_transfers_mean_ipc} show similar scaling for buffer writes. There is a clear discrepancy between the buffer reads, however this can easily be blamed on the considerable difference in buffer sizes.


\begin{figure}%
    \centering
    \subfloat[\centering Mean buffer write time]{{
        \resizebox{!}{160pt}{
        \input{img/figures/hotspot/buffer_writes_mean_ipc.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean buffer read time]{{
        \resizebox{!}{160pt}{
            \input{img/figures/hotspot/buffer_reads_mean_ipc.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean buffer transfer times for HotSpot}%
    \label{fig:hotspot_buffer_transfers_mean_ipc}%
\end{figure}


\begin{figure}%
    \centering
    \subfloat[\centering Mean buffer write time]{{
        \resizebox{!}{160pt}{
        \input{img/figures/pathfinder/buffer_writes_mean_ipc.tex}
    } 
    }}%
    \qquad
    \subfloat[\centering Mean buffer read time]{{
        \resizebox{!}{160pt}{
            \input{img/figures/pathfinder/buffer_reads_mean_ipc.tex}
        } 
    }}%
    \captionsetup{justification=centering}
    \caption{Mean buffer transfer times for PathFinder}%
    \label{fig:pathfinder_buffer_transfers_mean_ipc}%
\end{figure}

\subsection{Overall Performance Analysis}

At first glance, if we include the IPC overhead, our initial implementation of the HHAL and restructuring of the MANGO stack is certainly not competitive with state-of-the-art programming models such as CUDA and OpenCL. 

Communicating between multiple processes through sockets significantly reduces performance when working within the same cluster, as more efficient communication could be adopted. If the HHAL, Barbeque and the MANGO API host run on the same machine, all communication could be done through shared memory instead of a socket. In addition, kernel executions and buffer transfers could be done entirely through a library linked directly to the MANGO host, without the need of any IPC. Allowing the computer to work on in this sort of "hybrid" mode would let MANGO achieve throughput inline with the initial metrics we presented, which do not take into account IPC.

It is important to note however that some IPC will still be needed within the same computer, as both Barbeque and MANGO need access to the HHAL for different reasons. Barbeque needs to allocate and deallocate resources while MANGO needs to execute the kernels with these same allocated resources. As they do not co-exist in the same process (Barbeque always works as a daemon, which could be connected to more than just MANGO) and need to access the same HHAL information, it is a requirement for at least some bookkeeping of the HHAL to always exist as separate server.

Although this discussed approach works for a single cluster, it is not extensible to a distributed system. If the target device runs on a separate computer from the MANGO host, there is no shared memory available and no way to directly talk with the device through a simple library like it would be possible with the device physically attached to the host. 

For this reason, we first presented our measurements without taking into account IPC, as this is a fairer comparison between the different programming models. The CUDA and OpenCL implementations assume that the host will be connected directly to the accelerators, thus they do not need to implement any kind of external communication. However, once we introduce a second machine, the overhead will be similar, if not exactly the same, for any model used as it is the only way to coordinate the host and device across a distributed system.

By creating the HHAL in a client-server fashion we followed the approach used when creating the initial HN library, which allows the HHAL server to be easily distributed and run on a separate cluster. Once the platform matures, however, the improvements mentioned previously will be very important for the cases when the MANGO host and the HHAL run on a single machine. This topic is discussed further in section \ref{sub-sect:hhal-hybrid-mode}.

Improvements can also be made on the HHAL side, without taking into account IPC. First, the overheads experienced for kernel executions can be attributed to the CUDA device context assignment which is currently repeated for each kernel launch. This is necessary, as we want MANGO to be able to run a kernel on any of the available GPUs. However, as the CUDA device context is set on a per-thread basis, this overhead could be avoided. In principle it would be possible to create a separate thread for each available device and assign a fixed context to each one as soon as the HHAL server is up and running.

Second, buffer transfers could be made asynchronous. By making the HHAL server multithreaded and enqueueing buffer transfers in different CUDA streams a bigger portion of the available PCI-E bandwidth could be exploited, as well as allowing for the ability to overlap data transfers and kernel executions as seen in \cite{overlap-data-transfers-cuda}.

\subsection{Programmability}

The results for the HotSpot benchmark can be seen in table \ref{tab:hotspot-loc} while the ones for PathFinder are in table \ref{tab:pathfinder-loc}.

\begin{table}
    \centering
    \begin{tabular}{l|c|c|c|c|c|c}
    \textit{Model} & \textit{Kernel (LOC)} & \textit{Kernel (RD)} & \textit{Host (LOC)} & \textit{Host (RD)} & \textit{Total (LOC)} & \textit{Total (RD)} \\ \hline
    MANGO & 84 & 0\% & 190 & 0\% & 274 & 0\% \\
    CUDA & 84 & 0\% & 166 & -13\% & 250 & -9\% \\
    OpenCL & 84 & 0\% & 212 & 12\% & 296 & 8\%  
    \end{tabular}
    \captionsetup{justification=centering}
    \caption{Lines of code for HotSpot benchmark}
    \label{tab:hotspot-loc}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{l|c|c|c|c|c|c}
    \textit{Model} & \textit{Kernel (LOC)} & \textit{Kernel (RD)} & \textit{Host (LOC)} & \textit{Host (RD)} & \textit{Total (LOC)} & \textit{Total (RD)} \\ \hline
    MANGO & 59 & 0\% & 133 & 0\% & 192 & 0\% \\
    CUDA & 59 & 0\% & 108 & -19\% & 167 & -13\% \\
    OpenCL & 59 & 0\% & 188 & 41\% & 247 & 29\%  
    \end{tabular}
    \captionsetup{justification=centering}
    \caption{Lines of code for PathFinder benchmark}
    \label{tab:pathfinder-loc}
\end{table}

When comparing kernel LOC we can see that they are equal across all implementations of the same benchmark. As MANGO uses the same kernel code as the CUDA implementation, this is expected. In the case of OpenCL, its kernels are also optimized for GPU execution and thus follow the same access pattern as a CUDA kernel. The only differences among the kernels being CUDA and OpenCL specific keywords and functions, which have a 1-to-1 mapping between each other.

On the host side, the CUDA implementation gains the upper hand on MANGO, needing 9\% less code for HotSpot and 13\% less code for PathFinder. On the other hand OpenCL requires 8\% and 29\% more code for each respective benchmark. These differences are mostly related to the following factors:

\textbf{Kernel function calls:} the single source nature of CUDA code allows these implementations to call a kernel like any other function. Meanwhile MANGO requires creating multiple argument objects, one for each of the kernel inputs and grouping them into a \texttt{KernelArguments} object to be able to start the kernel execution. OpenCL faces a similar issue as it also needs explicit \texttt{setKernelArg} calls for each kernel input. This gives a big advantage to CUDA, with MANGO and OpenCL being very similar to each other.

\textbf{Kernel loading:} both MANGO and OpenCL need to load kernel code from an external file. For MANGO this only requires creating a \texttt{KernelFunction} object, loading a file (single call to the \texttt{load} function of a \texttt{KernelFunction}) and registering the kernel to the \texttt{Context}. Meanwhile OpenCL requests that the kernel code is provided as a C string, leaving the file loading code to the user, who also needs to make function calls to build the program and create a kernel object. The CUDA implementation is not required to do any of the previous work, as the kernel code can be called directly and is compiled along with the host code.

\textbf{Resource deallocations:} while all programming models need to explicitly request resource allocation for input and output buffers, MANGO does not leave the user with the responsibility to perform the inverse operations, at least not individually. When the MANGO implementations finish, they can simply call the context deallocation function and all requested resources will be correctly released. On the other hand, both OpenCL and CUDA require explicit release of resources. In the case of CUDA, this only entails calling \texttt{cudaFree} for each \texttt{cudaMalloc} call, for OpenCL it is much more involved, however. The programmer needs to release, on top of the allocated buffers, the following resources: \texttt{CommandQueue}, \texttt{Kernel}, \texttt{Program}, \texttt{Context}, a buffer for the program source string, a buffer for querying device ids and a buffer for querying platform ids.

\textbf{Device selection:} OpenCL requires manual querying of the available platforms on the host as well as the available devices in order to select the device to use for the benchmark. Both are multi-step processes requiring multiple function calls and host heap memory allocations. As CUDA only runs on NVIDIA GPUs, one only needs to select a particular device ID among the ones available, but that can also be skipped (and was, for our tests) if there is only a single GPU available or there is no preference in which GPU to run the kernel. Finally, MANGO does all this work automatically, needing no input from the user apart from providing the device kernels along with information about which platform they target (in this case NVIDIA). In the background, BBQUE and the HHAL will make sure to assign the kernel to run on the most suitable device.

\textbf{Error handling:} as both CUDA and OpenCL work with exit codes in order to communicate runtime errors, there is a need to perform explicit error handling at each function call in their benchmark implementations. For brevity, most of this error handling was extracted into preprocessor macros, so they do not contribute significantly to the total LOC. Some OpenCL calls however cannot be easily handled by a macro and need extra error handling code. Meanwhile, the last layer of the MANGO API maps runtime errors into exceptions so they can be handled more easily by the user.

A breakdown of LOC differences for these particular sections of the code in both benchmarks can be seen in tables \ref{tab:hotspot-factors-loc} and \ref{tab:pathfinder-factors-loc} which refer to HotSpot and PathFinder respectively. As shown here, the main disadvantage of MANGO over CUDA is due to the kernel call code. This could be improved by leveraging C++'s templates, allowing for a variety of argument types and quantities to be supplied directly to MANGO's \texttt{kernel\_launch} call. This will turn the implementation of the function significantly more complex, but will provide a much more concise API for the users of the platform.

\begin{table}
    \centering
    \begin{tabular}{l|c|c|c|c|c|c}
    \textit{Model} & \textit{Kernel call} & \textit{Kernel load} & \textit{Deallocations} & \textit{Device select} & \textit{Error handling} & \textit{Total} \\ \hline
    MANGO & 20 & 3 & 1 & 0 & 0 & 24 \\
    CUDA & 7 & 0 & 3 & 0 & 7 & 17 \\
    OpenCL & 16 & 16 & 10 & 14 & 14 & 70  
    \end{tabular}
    \captionsetup{justification=centering}
    \caption{Size of relevant sections of code in HotSpot benchmark}
    \label{tab:hotspot-factors-loc}
\end{table}

\begin{table}
    \centering
    \begin{tabular}{l|c|c|c|c|c|c}
    \textit{Model} & \textit{Kernel call} & \textit{Kernel load} & \textit{Deallocations} & \textit{Device select} & \textit{Error handling} & \textit{Total} \\ \hline
    MANGO & 15 & 3 & 1 & 0 & 0 & 19 \\
    CUDA & 6 & 0 & 3 & 0 & 7 & 16 \\
    OpenCL & 11 & 16 & 10 & 14 & 14 & 65  
    \end{tabular}
    \captionsetup{justification=centering}
    \caption{Size of relevant sections of code in PathFinder benchmark}
    \label{tab:pathfinder-factors-loc}
\end{table}

